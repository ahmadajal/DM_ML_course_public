{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Surprise library\n",
    "\n",
    "[Surprise](http://surpriselib.com/) is a Python scikit building and analyzing recommender systems that deal with explicit rating data. Its name stands for Simple Python RecommendatIon System Engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBasic\n",
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from collections import defaultdict\n",
    "from surprise import get_dataset_dir\n",
    "from surprise.model_selection import train_test_split\n",
    "import io\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will create an SVD model using the 100k dataset from MovieLens. This takes a few seconds to run so be patient!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First train an SVD algorithm on the movielens dataset.\n",
    "data = Dataset.load_builtin('ml-100k') # there are a couple of famous Rec System datasets available in this library\n",
    "trainset = data.build_full_trainset()\n",
    "algo = SVD()\n",
    "algo.fit(trainset)\n",
    "\n",
    "# Then predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "testset = trainset.build_anti_testset() # Return a list of ratings that can be used as a testset\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some examples of predictions\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some helper functions\n",
    "\n",
    "We have built the predictions. Now we can visualize them. We first write these helpers functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmdb_class import TMDB # The class to retrive the movie poster images\n",
    "\n",
    "def read_item_names():\n",
    "    '''Read the u.item file from MovieLens 100-k dataset and return two\n",
    "    mappings to convert raw ids into movie names and movie names into raw ids.\n",
    "    '''\n",
    "\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    name_to_rid = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "            name_to_rid[line[1]] = line[0]\n",
    "\n",
    "    return rid_to_name, name_to_rid\n",
    "\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    '''Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    '''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list) # This is used to group a sequence of key-value pairs into a dictionary of lists\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the recommendations\n",
    "\n",
    "We can see for each user what are the top recommended movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = get_top_n(predictions)\n",
    "top_n['943']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from IPython.display import Image\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "top_n = get_top_n(predictions, n=10)\n",
    "\n",
    "# Read the mappings raw id <-> movie name\n",
    "rid_to_name, name_to_rid = read_item_names()\n",
    "\n",
    "# Print the recommended items for user id 1\n",
    "uid = '1'\n",
    "user_ratings = top_n[uid]\n",
    "recommended_items = [iid for (iid, _) in user_ratings]\n",
    "print(uid, recommended_items)\n",
    "\n",
    "# Convert ids into names.\n",
    "item_names = [rid_to_name[rid]\n",
    "              for rid in recommended_items]\n",
    "\n",
    "print(uid, item_names)\n",
    "\n",
    "for name in item_names:\n",
    "    print(name)\n",
    "    clean_name = re.sub(r'\\([^)]*\\)', '', name) # this remove the year of the movie which is in between paranthesis\n",
    "    url = TMDB().get_poster_path_by_name(clean_name)\n",
    "    print(url)\n",
    "    if url:\n",
    "        display(Image(url=url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation using surprise\n",
    "This package also provides for you built-in cross-validation to split the data to multiple folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE'], cv=5, verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-based collaborative filtering with surprise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'pearson', #let's use pearson similarity which can be seen as mean-centered cosine similarity\n",
    "    'user_based': True #we will do user-based CF\n",
    "}\n",
    "knn_means = KNNWithMeans(k=40, min_k=1, sim_options=sim_options, verbose=False)\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(knn_means, data, measures=['RMSE'], cv=5, verbose=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision- Recall @k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    '''Return precision and recall at k metrics for each user.'''\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of recommended items in top k\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(((true_r >= threshold) and (est >= threshold))\n",
    "                              for (est, true_r) in user_ratings[:k])\n",
    "\n",
    "        # Precision@K: Proportion of recommended items that are relevant\n",
    "        precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 1\n",
    "\n",
    "        # Recall@K: Proportion of relevant items that are recommended\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 1\n",
    "\n",
    "    return precisions, recalls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.2)\n",
    "algo = SVD()\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "for k in range(10):\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=3.5) # rating > 3 = relevant, rating < 3 = irrelevant\n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    precision.append( sum(prec for prec in precisions.values()) / len(precisions) )\n",
    "    recall.append( sum(rec for rec in recalls.values()) / len(recalls) )\n",
    "\n",
    "plt.plot(range(10), recall, 'ro-', label=\"recall\")\n",
    "plt.plot(range(10), precision, 'go-', label=\"precision\")\n",
    "plt.title(\"precision and recall for SVD\")\n",
    "plt.legend()\n",
    "plt.show();\n",
    "\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=20, threshold=3.5)\n",
    "\n",
    "print(\"precision @ 20 for SVD\", sum(prec for prec in precisions.values()) / len(precisions))\n",
    "print(\"recall @ 20 for SVD\", sum(rec for rec in recalls.values()) / len(recalls))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = KNNWithMeans(k=40, min_k=1, sim_options=sim_options, verbose=False)\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "for k in range(10):\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=3.5) # rating > 3 = relevant, rating < 3 = irrelevant\n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    precision.append( sum(prec for prec in precisions.values()) / len(precisions) )\n",
    "    recall.append( sum(rec for rec in recalls.values()) / len(recalls) )\n",
    "\n",
    "\n",
    "plt.plot(range(10), recall, 'ro-', label=\"recall\")\n",
    "plt.plot(range(10), precision, 'go-', label=\"precision\")\n",
    "plt.legend()\n",
    "plt.title(\"precision and recall for user-based knn\")\n",
    "plt.show();\n",
    "\n",
    "precisions, recalls = precision_recall_at_k(predictions, k=20, threshold=3.5)\n",
    "\n",
    "print(\"precision @ 20 for user-based knn\", sum(prec for prec in precisions.values()) / len(precisions))\n",
    "print(\"recall @ 20 for user-based knn\", sum(rec for rec in recalls.values()) / len(recalls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## precision-recall curve\n",
    "We will now observe the area under precision recall curve for tow methods: SVD and KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import signature\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "for k in range(20):\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=3.5) \n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    precision.append( sum(prec for prec in precisions.values()) / len(precisions) )\n",
    "    recall.append( sum(rec for rec in recalls.values()) / len(recalls) )\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve for SVD');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo =  KNNWithMeans(k=40, min_k=1, sim_options=sim_options, verbose=False)\n",
    "\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "for k in range(20):\n",
    "    precisions, recalls = precision_recall_at_k(predictions, k=k, threshold=3.5) \n",
    "\n",
    "    # Precision and recall can then be averaged over all users\n",
    "    precision.append( sum(prec for prec in precisions.values()) / len(precisions) )\n",
    "    recall.append( sum(rec for rec in recalls.values()) / len(recalls) )\n",
    "\n",
    "# In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "step_kwargs = ({'step': 'post'}\n",
    "               if 'step' in signature(plt.fill_between).parameters\n",
    "               else {})\n",
    "plt.step(recall, precision, color='b', alpha=0.2,\n",
    "         where='post')\n",
    "plt.fill_between(recall, precision, alpha=0.2, color='b', **step_kwargs)\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall curve for user-based KNN');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning hyperr-parameters with surprise\n",
    "As we saw we have built-in cross-validation in this package. We can use this to tune the hyper-parameters of our recommender system, eg tuning the number of neighbours in KNN or the number of factors (or the reduced dimensionality) in SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVD_grid_search = GridSearchCV(SVD, param_grid={'n_factors': [50, 100, 200, 300]}, measures=['RMSE'], cv=5,\n",
    "                               refit=True, joblib_verbose=2, n_jobs=-1)\n",
    "SVD_grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best parameter:\", SVD_grid_search.best_params)\n",
    "print(\"best rmse: \", SVD_grid_search.best_score)\n",
    "# you can even see the whole cv results\n",
    "print(\"\\n\")\n",
    "SVD_grid_search.cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_grid_search = GridSearchCV(KNNWithMeans, param_grid={'k': [20, 30, 40, 50], \n",
    "                                                         'sim_options': {'name': ['pearson'], 'user_based': [True]}}, \n",
    "                               measures=['RMSE'], cv=5,\n",
    "                               refit=True, joblib_verbose=2, n_jobs=-1)\n",
    "KNN_grid_search.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best parameter:\", KNN_grid_search.best_params)\n",
    "print(\"best rmse: \", KNN_grid_search.best_score)\n",
    "# you can even see the whole cv results\n",
    "print(\"\\n\")\n",
    "KNN_grid_search.cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the best SVD model. We will use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_svd = SVD_grid_search.best_estimator['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name = \"best_model_svd\"\n",
    "pickle.dump(best_model_svd, open(file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = pickle.load(open(\"best_model_svd\", 'rb'))\n",
    "m.predict('6', '908')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
